{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Credit Risk Morgage Loans\nThe data is provided by [Home Credit](https://www.homecredit.net/about-us.asp), who provides lines of credit (loans) to the unbanked population. There are 307,511 rows of different credit information and 122 columns of feature variables. \n\nEach SK_ID_CURR in the test set, will predict a probability for the TARGET variable. The final prediction file should contain a header and have the following format:\nSK_ID_CURR,TARGET <br/>\n100001,0.1 <br/>\n100005,0.9 <br/>\n100013,0.2 <br/>\n\nUsing different models using AUC found the following:\n* Linear regression 0.7327\n* Decision tree 0.7215\n* Random forest 0.6312\n* Logistic regression 0.6145\n* Knn 0.5106 \n\n## Seven Datasets Summary\nOriginal dataset csv files can be found on [Kaggle](https://www.kaggle.com/c/home-credit-default-risk). The columns with first five rows will be shown below to view whenever a dataset is used. Therefore, one will not have to download the csv files. There are seven sources of data for this project which will be briefly\ndescribed below:\n* Train.csv: This is the most important dataset with 307,511 rows which are house data. There are 106 column features describing houses such as square feet and year built. The column TARGET column is an important feature to discuss. A 1 in this row means the loan struggled to payback. A 0 means the loan was did not default. Some of the features will need to be encoded numerical to test if they have high feature importance.\n* bureau.csv: Other previous credit data from other financial institutions. \n* bureau_balance.csv: Monthly bureau previous credits.\n* brevious_application.csv: Previous appliation loans.\n* POS_CASH_BALANCE.csv: Monthly data about previous cash loans. \n* credit_card_balance.csv: Monthly credit card data for clients with Home Credit.\n* installments_payment.csv: Payment history for previous loans.\n<br/> <br/>\n\n## View Train.csv Data\nThe training dataset is the most important dataset with over three-hundred thousand house prices that will be predicted at the very using using the best metrics predictive models with reduced error. The first five rows of the train.csv file will be shown below.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, cross_validate\nfrom statistics import mean\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom sklearn.datasets import make_classification\nfrom sklearn import ensemble\nimport sklearn.metrics as metrics\n#sample=r'/kaggle/input/home-credit-default-risk/sample_submission.csv'\n#cash=r'/kaggle/input/home-credit-default-risk/POS_CASH_balance.csv'\n#info='/kaggle/input/home-credit-default-risk/HomeCredit_columns_description.csv'\n#app=r'/kaggle/input/home-credit-default-risk/previous_application.csv'\n#cc=r'/kaggle/input/home-credit-default-risk/credit_card_balance.csv'\n#install=r'/kaggle/input/home-credit-default-risk/installments_payments.csv'\nbureau_balance=r'/kaggle/input/home-credit-default-risk/bureau_balance.csv'\ntrain=r'/kaggle/input/home-credit-default-risk/application_train.csv'\ntest=r'/kaggle/input/home-credit-default-risk/application_test.csv'\ndata=pd.read_csv(train) # (307511, 122)\ntest=pd.read_csv(test)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T07:21:31.687978Z","iopub.execute_input":"2022-02-20T07:21:31.688569Z","iopub.status.idle":"2022-02-20T07:21:41.427032Z","shell.execute_reply.started":"2022-02-20T07:21:31.688461Z","shell.execute_reply":"2022-02-20T07:21:41.426089Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Examine TARGET column\nHow many loans were not repaid? In train.csv a 0 stands for repaid and 1 stands for payment difficulties. The percent of loans that defauled was 0.081. This is somewhat unbalanced data so we must be careful when selecting what metrics to use to analyze the data. In addition, we must consider other data files for feature importance.","metadata":{}},{"cell_type":"code","source":"temp=data['TARGET'].value_counts()\nprint(temp)\npaid=temp[0]\nnotPaid=temp[1]\ndefault=round(notPaid/(paid+notPaid),3)\nprint(\"Percent of loans that defauled: \", default)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T07:21:41.428568Z","iopub.execute_input":"2022-02-20T07:21:41.428868Z","iopub.status.idle":"2022-02-20T07:21:41.449443Z","shell.execute_reply.started":"2022-02-20T07:21:41.428839Z","shell.execute_reply":"2022-02-20T07:21:41.447303Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Find missing values\nToo many missing values on a column will get the colunmn removed. In this case, there were about forty columns with more than 50% missing data. In total,there are 60 numeric columns with missing data, we need to interpret the Buraeu to find feature importance in order to engineer which columns are most worth keeping.","metadata":{}},{"cell_type":"code","source":"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ndf = data.select_dtypes(include=numerics) # (307511, 106)\n\n#search for columns with missing values:\ndef findNA():\n    print(\"Missing data by column as a percent:\")\n    findNA=df.isnull().sum().sort_values(ascending=False)/len(df)\n    print(findNA.head(40))\nfindNA() ","metadata":{"execution":{"iopub.status.busy":"2022-02-20T07:21:41.451065Z","iopub.execute_input":"2022-02-20T07:21:41.451714Z","iopub.status.idle":"2022-02-20T07:21:41.624433Z","shell.execute_reply.started":"2022-02-20T07:21:41.451669Z","shell.execute_reply":"2022-02-20T07:21:41.623349Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Remove columns and Fill Missing Values\nVariable number can be changed to delete a missing column with more than 20 NA values. Then, the dataframe must be filled in the mean for the remaining missing values. Since we need a final credit prediction for every credit loan, we can simply not delete any rows.","metadata":{}},{"cell_type":"code","source":"number=20 #remove col with  or more missing values\ndf = df[df.isnull().sum(axis=1) <= number] \ndf= df.fillna(df.mean())","metadata":{"execution":{"iopub.status.busy":"2022-02-20T07:21:41.627350Z","iopub.execute_input":"2022-02-20T07:21:41.627722Z","iopub.status.idle":"2022-02-20T07:21:41.886298Z","shell.execute_reply.started":"2022-02-20T07:21:41.627674Z","shell.execute_reply":"2022-02-20T07:21:41.885001Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Heat Map Correlations and Multicollinearity\nThere is no major multicollinearity. In fact, there are not many correlated variables. The following heatmap is set for correlations above .05 because there are so few variables that are highly correlated.","metadata":{}},{"cell_type":"code","source":"def printHeat():\n    corr = df.corr()\n    #print(corr)\n    y='TARGET'\n    highly_corr_features = corr.index[abs(corr[y])>0.05]\n    plt.figure(figsize=(10,10))\n    heat = sns.heatmap(df[highly_corr_features].corr(),annot=True,cmap=\"RdYlGn\")\n    top10=corr[y].sort_values(ascending=False).head(10)\n    print(heat)\n    print(\"Top 10 Correlations:\\n\", top10) # top ten correlations\nprintHeat()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T07:21:41.888146Z","iopub.execute_input":"2022-02-20T07:21:41.888499Z","iopub.status.idle":"2022-02-20T07:21:46.488149Z","shell.execute_reply.started":"2022-02-20T07:21:41.888454Z","shell.execute_reply":"2022-02-20T07:21:46.487192Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Split Data\nSplit the data set into training data and test data. TARGET will always be Y since it is the independent variable. A 1 is a troubled loan while a 0 equals a not distressed loan. ","metadata":{}},{"cell_type":"code","source":"df=df.reset_index()\nX=df.drop('TARGET', axis=1)\ny=df['TARGET'] #indepdent variable\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=13)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T07:21:46.489488Z","iopub.execute_input":"2022-02-20T07:21:46.489791Z","iopub.status.idle":"2022-02-20T07:21:46.713289Z","shell.execute_reply.started":"2022-02-20T07:21:46.489758Z","shell.execute_reply":"2022-02-20T07:21:46.712439Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Gradient Booster and Feature Importance\nThe amount of annuity and days_birth (age) are the two most highly correlated features. However, since this is unbalanced data there do not seem to be many feature importance to begin with.","metadata":{}},{"cell_type":"code","source":"from sklearn.inspection import permutation_importance\nfrom sklearn.ensemble import GradientBoostingClassifier,GradientBoostingRegressor\n\nparams = {\n \"n_estimators\": 5, \"max_depth\": 4, \"min_samples_split\": 5, \"learning_rate\": 0.01,\n}\n\nreg = ensemble.GradientBoostingRegressor(**params)\nreg.fit(X_train, y_train)\n\ny_pred = reg.predict(X_test)\ngbr_r2 = r2_score(y_test, y_pred).round(4) \nprint(\"Gradient boosting regression r2: \", gbr_r2) \n\nmse = mean_squared_error(y_test, reg.predict(X_test))\nprint(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))\n\n#FEATURE IMPORTANCE:\nnum=10 # How many features?\ncols=X.columns\nfeature_importance = reg.feature_importances_[:num]\nsorted_idx = np.argsort(feature_importance)[:num]\npos = np.arange(sorted_idx.shape[0]) + 0.5\nfig = plt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.barh(pos, feature_importance[sorted_idx], align=\"center\")\nplt.yticks(pos, np.array(cols)[sorted_idx])\nplt.title(\"Feature Importance (MDI)\")","metadata":{"execution":{"iopub.status.busy":"2022-02-20T07:21:46.714817Z","iopub.execute_input":"2022-02-20T07:21:46.715038Z","iopub.status.idle":"2022-02-20T07:21:55.198178Z","shell.execute_reply.started":"2022-02-20T07:21:46.715013Z","shell.execute_reply":"2022-02-20T07:21:55.197522Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Logistic Regression\nAUC for logistic regression is:  0.6145.\n\n The c paramter in logistic regression model by definition is the following: \"Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization\". Using 1 the default value for C or putting C at .01 did not change the AUC for the logistic regression.","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlogReg = LogisticRegression(solver='liblinear') #solver param gets rid of encoder error\n\n#Train the model and create predictions\nlogReg.fit(X_train, y_train)\n\n#use model to predict probability that given y value is 1:\ny_pred_proba = logReg.predict_proba(X_test)[::,1]\n\n#calculate AUC of model\nauc = round(metrics.roc_auc_score(y_test, y_pred_proba), 4 ) \nprint(\"AUC for logistic regression is: \", auc)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T07:21:55.199502Z","iopub.execute_input":"2022-02-20T07:21:55.200334Z","iopub.status.idle":"2022-02-20T07:22:00.839212Z","shell.execute_reply.started":"2022-02-20T07:21:55.200284Z","shell.execute_reply":"2022-02-20T07:22:00.835679Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Linear Regression\nDue to small Y indepdent variables AUC is the more accurate metric than r_squared. Since the linear regression, accuracy, and cross validate are all near .045 it seems there is no sign of overfitting.\n\nAUC for linear regression is:  0.7327 <br/>\nLinear regression r2 score:  0.0475 <br/>\nAccuracy:  0.0475 <br/>\n0.0489  linear regression cross validate mean <br/>","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression, Ridge, Lasso\n\nlrModel = LinearRegression()\nlrModel.fit(X_train, y_train)\n#print(model.coef_)    #print(model.intercept_)\n\n#Generate Predictions:\npredictions = lrModel.predict(X_test)\n\n# plt.scatter(y_test, predictions)\nplt.hist(y_test - predictions)\n\n#Performance measurement:\nimport sklearn.metrics as metrics\nfrom sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, r2_score\n#print(classification_report(y_test_data, predictions))\n#print(confusion_matrix(y_test_data, predictions))\n\nmetrics.mean_absolute_error(y_test, predictions)\nnp.sqrt(metrics.mean_squared_error(y_test, predictions))\n\n#use model to predict probability that given y value is 1:\n#y_pred_proba = lrModel.predit(X_test)[::,1]\n\n#calculate AUC of model\nauc = round( metrics.roc_auc_score(y_test, predictions), 4 ) \nprint(\"AUC for linear regression is: \", auc)\n\n#use model to predict probability that given y value is 1:\ny_pred_proba = lrModel.predict(X_test)\nr2 = r2_score(y_test, y_pred_proba).round(4) \nprint(\"Linear regression r2 score: \", r2)\n\n#CROSS VALIDATE TEST RESULTS:\nlr_score = lrModel.score(X_test, y_test).round(4)  # train test \nprint(\"Accuracy: \", lr_score)\nlr_cv = cross_validate(lrModel, X, y, cv = 5, scoring= 'r2')\nlr_cvMean=lr_cv['test_score'].mean().round(4)\nprint(lr_cvMean, \" linear regression cross validate mean\")","metadata":{"execution":{"iopub.status.busy":"2022-02-20T07:22:00.840845Z","iopub.execute_input":"2022-02-20T07:22:00.841340Z","iopub.status.idle":"2022-02-20T07:22:06.353165Z","shell.execute_reply.started":"2022-02-20T07:22:00.841292Z","shell.execute_reply":"2022-02-20T07:22:06.352210Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Decision Tree\nAUC for decision tree is:  0.7215.","metadata":{"execution":{"iopub.status.busy":"2022-02-18T21:50:17.902367Z","iopub.execute_input":"2022-02-18T21:50:17.903218Z","iopub.status.idle":"2022-02-18T21:50:17.906851Z","shell.execute_reply.started":"2022-02-18T21:50:17.903177Z","shell.execute_reply":"2022-02-18T21:50:17.905835Z"}}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\n#FIND best_tree_size LEAF NODES:\ndef get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=42)\n    model.fit(train_X, train_y)\n    preds_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y, preds_val)\n    return(mae)\n\ncandidate_max_leaf_nodes = [5, 25, 50, 100, 250, 500]\nmaeDic={} #dictionary  key=leaf  mae=value\nfor leaf in candidate_max_leaf_nodes:\n    mae=get_mae(leaf, X_train, X_test, y_train, y_test)\n    maeDic[leaf]=mae\n\nbest_tree_size = sorted(maeDic, key=lambda x : maeDic[x])[0]\n\n#MAKE PREDICTION:\ntree = DecisionTreeRegressor(max_leaf_nodes=best_tree_size, random_state=42)\ntree.fit(X, y)\ny_pred = tree.predict(X_test)\n\n#AUC and r2 metric:\ntree_r2 = r2_score(y_test, y_pred).round(4)\ntree_auc = round( metrics.roc_auc_score(y_test, y_pred), 4 ) \nprint(\"AUC for decision tree is: \", tree_auc)\n\ndef printReports(y_test, y_pred):\n    print(classification_report(y_test, y_pred))\n    print(confusion_matrix(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-02-20T07:22:06.356262Z","iopub.execute_input":"2022-02-20T07:22:06.356552Z","iopub.status.idle":"2022-02-20T07:22:25.643275Z","shell.execute_reply.started":"2022-02-20T07:22:06.356517Z","shell.execute_reply":"2022-02-20T07:22:25.642399Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest Regressor","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\ndMAE={} #dictionary of n_estimators as key and MAE as value:\ndef checkMAE():\n    for n in range(100, 1401, 100):\n        forest = RandomForestRegressor(n_estimators=n, random_state = 0)\n        forest.fit(X_train, y_train)\n        y_pred = forest.predict(X_test)\n        MAE=metrics.mean_absolute_error(y_test, y_pred).round(2)\n        dMAE[n]=MAE\n        #print(\"n_estimates: \", n,  '  Mean Absolute Error:', MAE)\n\n    dMAE=sorted(((v, k) for k, v in dMAE.items()), reverse=False)\n    #print(dMAE) #[(18573.45, 400), (18632.04, 200), (18636.62, 500), (18644.81, 300), (18651.96, 600),\n\nnum=10\nforest = RandomForestRegressor(n_estimators=num, random_state = 0)\nforest.fit(X_train, y_train)\ny_pred = forest.predict(X_test)\n\n#Print Metrics:\nforest_r2 = r2_score(y_test, y_pred).round(4) \nprint(\"Random forest r2: \", forest_r2) \nforest_auc = round( metrics.roc_auc_score(y_test, y_pred), 4 ) \nprint(\"Random forest AUC: \", forest_auc) ","metadata":{"execution":{"iopub.status.busy":"2022-02-20T07:28:38.977164Z","iopub.execute_input":"2022-02-20T07:28:38.977458Z","iopub.status.idle":"2022-02-20T07:29:44.643311Z","shell.execute_reply.started":"2022-02-20T07:28:38.977426Z","shell.execute_reply":"2022-02-20T07:29:44.642320Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## K-Nearest Neighbors\nFirst, we must select the optimal K value with the least amount of error. When graphing the error rates, 3 is the knn that provides the least amount of error. The final AUC result was 0.5184 which was the worse predictive model. ","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\n#Selecting an optimal K value:\nerror_rates = []\nfor i in range(1, 10, 2): #Must be an odd number to break a tie\n    new_model = KNeighborsClassifier(n_neighbors = i)\n    new_model.fit(X_train, y_train)\n    new_predictions = new_model.predict(X_test)\n    error_rates.append(np.mean(new_predictions != y_test))\nplt.figure(figsize=(16,12))\nplt.plot(error_rates)\n\n#Train the model and make predictions:\nknn = KNeighborsClassifier(n_neighbors =3) \nknn.fit(X_train, y_train)\nknnPredict = knn.predict_proba(X_test)[::,1]\n\n#calculate AUC of model\nknn_auc = round( metrics.roc_auc_score(y_test, knnPredict), 4 ) \nprint(\"Knn AUC: \", knn_auc)\n\ndef knnReports():\n    acc = metrics.accuracy_score(y_test_data, knnPredict)\n    print(confusion_matrix(y_test, knnPredict))\n    print(classification_report(y_test, knnPredict))\n    print(confusion_matrix(y_test, knnPredict))","metadata":{"execution":{"iopub.status.busy":"2022-02-20T07:34:13.648150Z","iopub.execute_input":"2022-02-20T07:34:13.648476Z","iopub.status.idle":"2022-02-20T07:36:11.756453Z","shell.execute_reply.started":"2022-02-20T07:34:13.648444Z","shell.execute_reply":"2022-02-20T07:36:11.755547Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Support Vector Machine (SVM)\nWith a large number of samples, SVM is extremely slow and cannot really be used. This is a major disavantage of SVM and why some do not use it. This seems to be the case this this problem too. For more information on why SVM is slow here is a stack overflow article: https://stackoverflow.com/questions/40077432/why-is-scikit-learn-svm-svc-extremely-slow","metadata":{}},{"cell_type":"code","source":"def trySVM():\n    from sklearn.svm import SVC\n    \n    svc = SVC()\n    svc.fit(X_train, y_train)\n\n    #use model to predict probability that given y value is 1:\n    svc_predit = svc.predict(X_test)\n\n    #calculate AUC of model\n    auc = round( metrics.roc_auc_score(y_test, svc_predit), 4 ) \n    print(\"SVC AUC is: \", auc)\n\n    def svmReports():\n        print(classification_report(y_test, svc_predit))\n        print(confusion_matrix(y_test, svc_predit))\n        metrics.mean_absolute_error(y_test, svc_predit)\n        metrics.mean_squared_error(y_test, svc_predit)\n        np.sqrt(metrics.mean_squared_error(y_test, svc_predit))","metadata":{"execution":{"iopub.status.busy":"2022-02-20T07:24:09.219909Z","iopub.status.idle":"2022-02-20T07:24:09.220639Z","shell.execute_reply.started":"2022-02-20T07:24:09.220378Z","shell.execute_reply":"2022-02-20T07:24:09.220411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Final Credit Risk Prediction\nAll 307,511 credit loans from the train dataset will get a final credit risk prediction. Since linear regression seemed to have good AUC results, I will use linear for the final prediction.","metadata":{}},{"cell_type":"code","source":"# log-transform y to train and exp-transform the predictions:\nlrModel.fit(X_train, np.log(y_train))\nfinal_predictions = np.exp(lrModel.predict(X_test))\n\noutput = pd.DataFrame({'SK_ID_CURR': X_test.SK_ID_CURR, 'CreditRisk': final_predictions})\nprint(output.shape) #(1446, 2)\noutput.head()\n\noutput.to_csv('creditRiskSubmit.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"execution":{"iopub.status.busy":"2022-02-20T07:24:09.221770Z","iopub.status.idle":"2022-02-20T07:24:09.222108Z","shell.execute_reply.started":"2022-02-20T07:24:09.221941Z","shell.execute_reply":"2022-02-20T07:24:09.221958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Extra: Buraeu Data \nThe Buraeu data has [1716428 rows x 17 columns]. Three columns were categorical so they get removed.\nThen an additional four columns had lots of missing data, more than 80% so they are deleted.\nFinally, we remove a small portion of missing values just to get a general analysis of the missing data.\nThe goal is to use this additional information outside of the train set to try to find feature importance.","metadata":{}},{"cell_type":"code","source":"buraeuData=r'/kaggle/input/home-credit-default-risk/bureau.csv'\nburaeuDF=pd.read_csv(buraeuData) #[1716428 rows x 17 columns]\n\nnumerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nburaeuDF = buraeuDF.select_dtypes(include=numerics) #(1716428, 14)\n# Six columns have missing values:\nbNA=buraeuDF.isnull().sum().sort_values(ascending=False)/len(buraeuDF) \nburaeuDF=buraeuDF.dropna(thresh=0.8*len(buraeuDF), axis=1) #(1716428, 10)\nburaeuDF = buraeuDF.dropna() #(1376391, 10)\nhead=buraeuDF.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T07:24:09.223986Z","iopub.status.idle":"2022-02-20T07:24:09.224380Z","shell.execute_reply.started":"2022-02-20T07:24:09.224156Z","shell.execute_reply":"2022-02-20T07:24:09.224174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Resources\n1. https://www.kaggle.com/willkoehrsen/start-here-a-gentle-introduction","metadata":{}}]}