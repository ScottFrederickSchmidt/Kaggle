'''
An updated verision that contains visual graphs will be located here:  
https://www.kaggle.com/scottfredschmidt/predict-housing-prices/edit

Real data with 79 explanatory variables describing aspects of residential homes in Ames, Iowa.
The final price of each home is predicted using:
1) Realative feature engineering,
2) Advanced regression techniques (random forest and gradient boosting).
'''
import os
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

print("start")

data=pd.read_csv(r'C:\Users\sschm\Desktop\HousePrice/train.csv') #(1459, 80)

cols=['MSSubClass', 'LotArea', 'OverallQual','OverallCond','YearBuilt', 'MoSold', 
             'YrSold', 'MasVnrArea', 'BsmtFinSF1','BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', '1stFlrSF', '2ndFlrSF',
             'GrLivArea','WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch','3SsnPorch', 'ScreenPorch','PoolArea', 'SalePrice'
            ]

df = pd.DataFrame(data, columns=cols) 
df = df[df.isnull().sum(axis=1) <= 5] #remove col with 5 or more missing values
df = df.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)
X=df.drop('SalePrice', axis=1)
y=df['SalePrice']

#Find Multicollinearity using VIF:
from statsmodels.stats.outliers_influence import variance_inflation_factor
def calc_VIF(x):
    vif= pd.DataFrame()
    vif['variables']=x.columns
    vif["VIF"]=[variance_inflation_factor(x.values,i) for i in range(x.shape[1])]
    return(vif)

#Find Multicollinearity using heat map:
def printHeat():
    corr = df.corr()
    #print(corr)
    highly_corr_features = corr.index[abs(corr["SalePrice"])>0.5]
    plt.figure(figsize=(10,10))
    heat = sns.heatmap(df[highly_corr_features].corr(),annot=True,cmap="RdYlGn")
    top10=corr["SalePrice"].sort_values(ascending=False).head(10)
    print(heat)
    print(top10)

def pltFigure():
    fig = plt.figure(figsize=(12,10))
    #GarageArea
    plt.subplot(321)
    sns.scatterplot(data=train, x='GarageArea', y="SalePrice")

#Sorting columns null values:
def findNA():
    findNA=df.isna().sum()  #check = df[''].value_counts()
    total=data.isnull().sum().sort_values(ascending=False)
    total=total.head(20)
#printHeat()  #will print heatmap and correlations
#calc_VIF(df[::-1]) #test for multicollinearity using VIF
#pltFigure() #plot figures


#Split the data set into training data and test data:
from sklearn.model_selection import train_test_split, cross_validate
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from statistics import mean
​
x_train_data, x_test_data, y_train_data, y_test_data = train_test_split(X, y, test_size = 0.3, random_state=42)
​
lrModel = LinearRegression()
lrModel.fit(x_train_data, y_train_data)
#print(model.coef_)
#print(model.intercept_)
​
#Generate Predictions:
predictions = lrModel.predict(x_test_data)
​
# plt.scatter(y_test, predictions)
plt.hist(y_test_data - predictions)
​
#Performance measurement:
import sklearn.metrics as metrics
from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, r2_score
#print(classification_report(y_test_data, predictions))
#print(confusion_matrix(y_test_data, predictions))
​
metrics.mean_absolute_error(y_test_data, predictions)
metrics.mean_squared_error(y_test_data, predictions)
np.sqrt(metrics.mean_squared_error(y_test_data, predictions))
​
#use model to predict probability that given y value is 1:
y_pred_proba = lrModel.predict(x_test_data)
​
#calculate AUC
#auc = round( metrics.roc_auc_score(y_test_data, y_pred_proba, multi_class='ovr'), 4 ) 
#print(auc, " AUC ", )
​
r2 = r2_score(y_test_data, y_pred_proba).round(4) 
print("r2 score: ", r2)
​
#Cross Validation Test Results:
lr_score = lrModel.score(X_test, y_test).round(4)  # train test 
print("Accuracy: ", lr_score)
lr_cv = cross_validate(lrModel, X, y, cv = 5, scoring= 'r2')
#print("Cross-validation results: ", lr_cv)
#print("R2 Cross-validation: ", np.array(list(lr_cv.values())).mean().round(4) ) 
​
#RIDGE REGRESSION:
ridge = Ridge(alpha = 1)  # sets alpha to a default value as baseline  
ridge.fit(X_train, y_train)
​
ridge_cv = cross_validate(ridge, X, y, cv = 5, scoring = 'r2')
print ("Cross-validation results: ", ridge_cv)
print ("Ridge Regression R2: ", ridge_cv.mean())

#LASSO REGRESSION:
lasso = Lasso(alpha = .1, normalize=True)  # sets alpha to almost zero as baseline
lasso.fit(x_train_data, y_train_data)
lasso_cv = cross_validate(lasso, X, y, cv = 5, scoring = 'r2')
lasso_cvMean=lasso_cv['test_score'].mean().round(4)
#print ("Lasso Regression R2: ", lasso_cvMean)

'''
Create a predition using random forest
Splitting the dataset into the Training set and Test set
'''
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)

# Fitting Random Forest Regression to the Training set
from sklearn.ensemble import RandomForestRegressor
import sklearn.metrics as metrics
from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix

dMAE={}
for n in range(250, 1401, 250):
    regressor = RandomForestRegressor(n_estimators=n, random_state = 0)
    regressor.fit(X_train, y_train)
    #score=clf.score(X_test,y_test)
    #print("score: ", score)

    # Predicting the Test set results
    y_pred = regressor.predict(X_test)
    #y_pred1= regressor.predict(X_test)[:,1]

    #auc = metrics.roc_auc_score(y_test, y_pred)
    #auc = metrics.roc_auc_score(y_test, y_pred)
    #print("AUC: ", auc)

    # Evaluating the Algorithm
    MAE=metrics.mean_absolute_error(y_test, y_pred).round(3)
    dMAE[n]=MAE
    #print("n_estimates: ", n)
    #print('Mean Absolute Error:', MAE)  
    #print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred).round(3))  
    #print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)).round(3))

#sort dictionary by values and find the lowest MAE:
#dMAE=sorted(((v, k) for k, v in dMAE.items()), reverse=True)[:5]
print(dMAE)
dMAE=sorted(((v, k) for k, v in dMAE.items()), reverse=True)
print(dMAE)
print("done")

'''
start
{250: 18632.242, 500: 18636.621, 750: 18680.353, 1000: 18696.357, 1250: 18674.225}
[(18696.357, 1000), (18680.353, 750), (18674.225, 1250), (18636.621, 500), (18632.242, 250)]
done

TOP CORRELATIONS to SalesPrice:
OverallQual    0.789997
GrLivArea      0.710080
TotalBsmtSF    0.612971
1stFlrSF       0.606849
YearBuilt      0.522896
MasVnrArea     0.477493
BsmtFinSF1     0.383977
WoodDeckSF     0.324650
2ndFlrSF       0.322710


n_estimates:  50
Mean Absolute Error: 19072.341
Mean Squared Error: 873847863.072
Root Mean Squared Error: 29560.918

n_estimates:  100
Mean Absolute Error: 18723.521
Mean Squared Error: 848083216.583
Root Mean Squared Error: 29121.868

n_estimates:  150
Mean Absolute Error: 18570.264
Mean Squared Error: 839489900.342
Root Mean Squared Error: 28973.952

n_estimates:  200
Mean Absolute Error: 18632.043
Mean Squared Error: 836170652.963
Root Mean Squared Error: 28916.616

n_estimates:  250
Mean Absolute Error: 18632.242
Mean Squared Error: 842502190.106
Root Mean Squared Error: 29025.888
'''
