'''
Decision Tree:   Drugs A, B, C, X, Y    Dataset Kaggle
'''
import pandas as pd
import numpy as np
import time

#Visalization libraries:
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline

''' STEP1: CLEAN THE DATA '''
data=r'C:\Users\sschm\Desktop\drug200.csv' 
df=pd.read_csv(data)

#Change feature variables to a numeric value:
df['Sex'] = df['Sex'].map({'M':1 ,'F':0})
df['BP'] = df['BP'].map({'HIGH':1 ,'NORMAL':.5, 'LOW':0})
df['Cholesterol'] = df['Cholesterol'].map({'HIGH':1 ,'NORMAL':.5, 'LOW':0})

start=time.time()
print("Starting decision tree.")

df.dropna(inplace=True) #delete any rows with missing values the simple way.

''' STEP2: TRAIN THE DATA '''

#Split the data set into training data and test data
from sklearn.model_selection import train_test_split
x = df.drop('Drug', axis = 1)
y = df['Drug']
x_training_data, x_test_data, y_training_data, y_test_data = train_test_split(x, y, test_size = 0.3, random_state=42)

#Train the decision tree model
from sklearn.tree import DecisionTreeClassifier
model = DecisionTreeClassifier()
model.fit(x_training_data, y_training_data)
predictions = model.predict(x_test_data)
print(predictions)

''' STEP3: PREDICT THE DATA '''
#Measure the performance of the decision tree model
from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, r2_score
print(classification_report(y_test_data, predictions))
print(confusion_matrix(y_test_data, predictions))

#Performance measurement:
import sklearn.metrics as metrics
from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix
#print(classification_report(y_test_data, predictions))
#print(confusion_matrix(y_test_data, predictions))

metrics.mean_absolute_error(y_test_data, predictions)
metrics.mean_squared_error(y_test_data, predictions)
np.sqrt(metrics.mean_squared_error(y_test_data, predictions))


print(classification_report(y_test_data, predictions))
print(confusion_matrix(y_test_data, predictions))

#use model to predict probability that given y value is 1:
y_pred_proba = model.predict(x_test_data)

#calculate AUC of model
auc = round( metrics.roc_auc_score(y_test_data, y_pred_proba), 4 ) 
print("AUC is: ", auc)
