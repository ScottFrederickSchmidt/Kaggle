{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# M5 Forecasting - Accuracy\n#### Estimate the unit sales of Walmart retail goods\nHow much camping gear will one store sell each month in a year? To the uninitiated, calculating sales at this level may seem as difficult as predicting the weather. Both types of forecasting rely on science and historical data. While a wrong weather forecast may result in you carrying around an umbrella on a sunny day, inaccurate business forecasts could result in actual or opportunity losses. In this competition, in addition to traditional forecasting methods you’re also challenged to use machine learning to improve forecast accuracy.\n\nUse hierarchical sales data from Walmart, the world’s largest company by revenue, to forecast daily sales for the next 28 days. The data, covers stores in three US States (California, Texas, and Wisconsin) and includes item level, department, product categories, and store details. In addition, it has explanatory variables such as price, promotions, day of the week, and special events. Together, this robust dataset can be used to improve forecasting accuracy.\n\nIf successful, your work will continue to advance the theory and practice of forecasting. The methods used can be applied in various business areas, such as setting up appropriate inventory or service levels. Through its business support and training, the MOFC will help distribute the tools and knowledge so others can achieve more accurate and better calibrated forecasts, reduce waste and be able to appreciate uncertainty and its risk implications.\n\nThe original dataset and information can be found on Kaggle here:\nhttps://www.kaggle.com/competitions/m5-forecasting-accuracy","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\ncalendar=r'/kaggle/input/m5-forecasting-accuracy/calendar.csv'\nsample=r'/kaggle/input/m5-forecasting-accuracy/sample_submission.csv'\nsellData=r'/kaggle/input/m5-forecasting-accuracy/sell_prices.csv'\ntrainVal=r'/kaggle/input/m5-forecasting-accuracy/sales_train_validation.csv'\ntrainEval=r'/kaggle/input/m5-forecasting-accuracy/sales_train_evaluation.csv'","metadata":{"execution":{"iopub.status.busy":"2022-04-04T02:01:55.767435Z","iopub.execute_input":"2022-04-04T02:01:55.767985Z","iopub.status.idle":"2022-04-04T02:01:55.795935Z","shell.execute_reply.started":"2022-04-04T02:01:55.767893Z","shell.execute_reply":"2022-04-04T02:01:55.795131Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"This competition uses a Weighted Root Mean Squared Scaled Error (RMSSE).\nExtensive details about the metric, scaling, and weighting can be found in the M5 Participants Guide.","metadata":{}},{"cell_type":"markdown","source":"## Evaluation Data\nThe train evaluation data has 30490 rows × 1947 columns. Model Evaluation is an essential part of the model development process that is also known as the train dataset. ","metadata":{}},{"cell_type":"code","source":"train=pd.read_csv(trainEval)\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-04-04T02:01:55.801211Z","iopub.execute_input":"2022-04-04T02:01:55.801820Z","iopub.status.idle":"2022-04-04T02:02:04.266998Z","shell.execute_reply.started":"2022-04-04T02:01:55.801775Z","shell.execute_reply":"2022-04-04T02:02:04.265973Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Validation Data\nThere are 130490 rows × 1919 columns. Validation is the test set. Model validation confirms the models are performing as expected and the models are sound.","metadata":{}},{"cell_type":"code","source":"test=pd.read_csv(trainVal)\ntest","metadata":{"execution":{"iopub.status.busy":"2022-04-04T02:02:04.269541Z","iopub.execute_input":"2022-04-04T02:02:04.269901Z","iopub.status.idle":"2022-04-04T02:02:11.524202Z","shell.execute_reply.started":"2022-04-04T02:02:04.269859Z","shell.execute_reply":"2022-04-04T02:02:11.523159Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sell=pd.read_csv(sellData)\nsell","metadata":{"execution":{"iopub.status.busy":"2022-04-04T02:02:11.525469Z","iopub.execute_input":"2022-04-04T02:02:11.525706Z","iopub.status.idle":"2022-04-04T02:02:17.366536Z","shell.execute_reply.started":"2022-04-04T02:02:11.525678Z","shell.execute_reply":"2022-04-04T02:02:17.365715Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Make Final Prediction\nSubmission File\nEach row contains an id that is a concatenation of an item_id and a store_id, which is either validation (corresponding to the Public leaderboard), or evaluation (corresponding to the Private leaderboard). You are predicting 28 forecast days (F1-F28) of items sold for each row. For the validation rows, this corresponds to d_1914 - d_1941, and for the evaluation rows, this corresponds to d_1942 - d_1969. (Note: a month before the competition close, the ground truth for the validation rows will be provided.)\n\nThe files must have a header and should look like the following:","metadata":{}},{"cell_type":"code","source":"sample=pd.read_csv(sample)\nsample","metadata":{"execution":{"iopub.status.busy":"2022-04-04T02:02:17.368161Z","iopub.execute_input":"2022-04-04T02:02:17.368395Z","iopub.status.idle":"2022-04-04T02:02:17.601107Z","shell.execute_reply.started":"2022-04-04T02:02:17.368366Z","shell.execute_reply":"2022-04-04T02:02:17.600284Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## References\n1. https://www.kaggle.com/code/minhajulhoque/deep-learning-rnn-for-m5-forecasting","metadata":{}}]}